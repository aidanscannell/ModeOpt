scenario: 5
env_name: velocity-controlled-point-mass/scenario-${scenario}

dynamics:
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.04/164628/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.14/113746/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.14/141940/ckpts/ModeOptDynamics
  ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.16/111750/ckpts/ModeOptDynamics
  control_dim: 2
  state_dim: 2
  desired_mode: 1

cost_fn:
  # terminal_state_cost_matrix: [[100.0, 0.0], [0.0, 100.0]]  # Q_terminal
  terminal_state_cost_matrix: [[50.0, 0.0], [0.0, 50.0]]  # Q_terminal
  # control_cost_matrix: [[0.05, 0.0], [0.0, 0.05]] # R
  control_cost_matrix: [[0.1, 0.0], [0.0, 0.1]] # R
  # control_cost_matrix: [[0.5, 0.0], [0.0, 0.5]] # R
  # control_cost_matrix: [[1.0, 0.0], [0.0, 1.0]] # R

start_state: [2.5, -1.85]
# start_state: [3.0, -2.0]
# start_state: [2.5, -1.85]
# target_state: [-2.9, 2.0]
target_state: [-3.1, 2.8]
# target_state: [-2.7, 3.0]
max_iterations: 1000
# max_iterations: 1
horizon: 20
# control_constraints_lower: [-5, -5]
# control_constraints_upper: [5, 5]
method: "SLSQP" # or "SLSQP" or "L-BFGS-B"
gaussian_controls: true

logging_freq: 10

hydra:
  run:
    dir: velocity_controlled_point_mass/experiments/scenario_${scenario}/trajectory_optimisation/control_as_inference/${now:%Y.%m.%d}/${now:%H%M%S}
