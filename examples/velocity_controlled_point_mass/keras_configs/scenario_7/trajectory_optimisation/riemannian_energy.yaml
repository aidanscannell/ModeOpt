scenario: 7

dynamics:
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.02.19/123734/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_continue_training_dynamics/2022.02.22/092500/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.02.22/122632/ckpts/ModeOptDynamics
  ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.02.22/132351/ckpts/ModeOptDynamics
  control_dim: 2
  state_dim: 2
  # desired_mode: 0
  desired_mode: 1

cost_fn:
  # riemannian_metric_cost_matrix: [[1.0, 0.0], [0.0, 1.0]] # G: \E[G(state)] @ riemannian_metric_cost_weight
  riemannian_metric_cost_matrix: [[10.0, 0.0], [0.0, 10.0]] # G: \E[G(state)] @ riemannian_metric_cost_weight
  # riemannian_metric_covariance_weight: 1.0
  # riemannian_metric_covariance_weight: 10.0
  riemannian_metric_covariance_weight: 0.001
  # riemannian_metric_covariance_weight: 0.1
  terminal_state_cost_matrix: [[1000.0, 0.0], [0.0, 1000.0]]  # Q_terminal
  control_cost_matrix: [[1.0, 0.0], [0.0, 1.0]] # R
  # control_cost_matrix: [[0.01, 0.0], [0.0, 0.01]] # R
  # control_cost_matrix: [[0.1, 0.0], [0.0, 0.1]] # R

env_name: velocity-controlled-point-mass/scenario-${scenario}

start_state: [0.5, -2.0]
target_state: [2.2, 2.5]
num_iterations: 1000
# horizon: 10
horizon: 20
control_constraints_lower: [-5, -5]
control_constraints_upper: [5, 5]
gaussian_controls: false
method: "SLSQP" # or "SLSQP" or "L-BFGS-B"

hydra:
  run:
    dir: velocity_controlled_point_mass/experiments/scenario_${scenario}/trajectory_optimisation/riemannian_energy/${now:%Y.%m.%d}/${now:%H%M%S}
