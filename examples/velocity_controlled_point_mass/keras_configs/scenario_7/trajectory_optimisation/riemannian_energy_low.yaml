scenario: 7
env_name: velocity-controlled-point-mass/scenario-${scenario}

dynamics:
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.02.22/132351/ckpts/ModeOptDynamics
  ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.04/164628/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.08/101028/ckpts/ModeOptDynamics
  # ckpt_dir: ../../../../../scenario_${scenario}/mode_opt_train_dynamics/2022.03.08/141209/ckpts/ModeOptDynamics
  control_dim: 2
  state_dim: 2
  desired_mode: 1

cost_fn:
  riemannian_metric_cost_matrix: [[1.0, 0.0], [0.0, 1.0]] # G: \E[G(state)] @ riemannian_metric_cost_weight
  # riemannian_metric_cost_matrix: [[10.0, 0.0], [0.0, 10.0]] # G: \E[G(state)] @ riemannian_metric_cost_weight
  # riemannian_metric_covariance_weight: 0.01
  riemannian_metric_covariance_weight: 0.5
  terminal_state_cost_matrix: [[1000.0, 0.0], [0.0, 1000.0]]  # Q_terminal
  control_cost_matrix: [[1.0, 0.0], [0.0, 1.0]] # R
  # control_cost_matrix: [[0.1, 0.0], [0.0, 0.1]] # R


start_state: [0.5, -2.0]
# target_state: [2.2, 2.5]
target_state: [1.7, 3.0]
max_iterations: 1000
# horizon: 10
horizon: 20
control_constraints_lower: [-5, -5]
control_constraints_upper: [5, 5]
gaussian_controls: false
method: "SLSQP" # or "SLSQP" or "L-BFGS-B"

logging_freq: 10

hydra:
  run:
    dir: velocity_controlled_point_mass/experiments/scenario_${scenario}/trajectory_optimisation/riemannian_energy_low/${now:%Y.%m.%d}/${now:%H%M%S}
