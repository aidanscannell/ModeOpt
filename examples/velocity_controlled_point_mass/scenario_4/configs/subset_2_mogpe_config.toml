num_samples = 1 # number of samples to approximate variational expectation with
num_experts = 2
# bound = "tight" # which ELBO to use, either "tight" or "further", default is "further"
# bound = "further" # which ELBO to use, either "tight" or "further", default is "further"
bound = "further_gating" # which ELBO to use, either "tight" or "further", default is "further"

[[experts]]
    name = "expert_1" # specify a name
    whiten = true # boolean, if true, use whitened representation of inducing points
    [experts.mean_function]
        name = "constant" # mean function e.g. options are "constant" or "zero"
        [experts.mean_function.params] # set required parameters for the kernel type
            constant = [0.0, 0.0] # constant value
    [experts.kernel]
        name = "rbf" # kernel type e.g. "rbf", "cosine", "sum", "product"
        [experts.kernel.params] # set required parameters for the kernel type
            lengthscale = 10.0 # RBF lengthscale
            variance = 0.1 # RBF signal variance
    [experts.likelihood]
        name = "gaussian" # likelihood type, "gaussian" is only valid option
        [experts.likelihood.params] # set required parameters for the likelihood type
            variance = [0.0011, 0.0011] # Guassian noise variance
    [experts.inducing_points]
        inputs_trainable = true
        num_inducing = 90
        q_mu.mean = 0.0 # mean of variational Gaussian posterior, will be broadcast to correct shape
        q_mu.var = 2.0 # add Gaussian noise to mean of variational Gaussian posterior to aid training N(0,q_mu.var)
        q_sqrt = 1.0 # cholesky of covariance of variational Gaussian posterior, will be multiplied by identity of correct shape
        q_diag = false # boolean, if true, approximate covariance by diagonal matrix

[[experts]]
    name = "expert_2" # specify a name
    whiten = true # boolean, if true, use whitened representation of inducing points
    [experts.mean_function]
        name = "constant" # mean function e.g. options are "constant" or "zero"
        [experts.mean_function.params] # set required parameters for the kernel type
            constant = [0.0, 0.0] # constant value
    [experts.kernel]
        name = "rbf" # kernel type e.g. "rbf", "cosine", "sum", "product"
        [experts.kernel.params] # set required parameters for the kernel type
            lengthscale = 0.5 # RBF lengthscale
            variance = 20.0 # RBF signal variance
    [experts.likelihood]
        name = "gaussian" # likelihood type, "gaussian" is only valid option
        [experts.likelihood.params] # set required parameters for the likelihood type
            variance = [1.9, 1.9] # Guassian noise variance
    [experts.inducing_points]
        inputs_trainable = true
        num_inducing = 90
        q_mu.mean = 0.0 # mean of variational Gaussian posterior, will be broadcast to correct shape
        q_mu.var = 2.0 # add Gaussian noise to mean of variational Gaussian posterior to aid training N(0,q_mu.var)
        q_sqrt = 1.0 # cholesky of covariance of variational Gaussian posterior, will be multiplied by identity of correct shape
        q_diag = false # boolean, if true, approximate covariance by diagonal matrix

[gating_network]
    whiten = true # boolean, if true, use whitened representation of inducing points
    [gating_network.mean_function]
        name= "zero" # mean function e.g. options are "constant" or "zero"
    [gating_network.kernel]
        name = "rbf" # kernel type e.g. "rbf", "cosine", "sum", "product"
        [gating_network.kernel.params] # set required parameters for the kernel type
            # lengthscale = 0.5 # RBF lengthscale
            # lengthscale = 5.0 # RBF lengthscale
            lengthscale = 10.0 # RBF lengthscale
            variance = 5.0 # RBF signal variance
            # variance = 100.0 # RBF signal variance
            # variance = 600.0 # RBF signal variance
    [gating_network.inducing_points]
        # inputs_trainable = false
        inputs_trainable = true
        num_inducing = 90
        q_mu.mean = 0.0 # mean of variational Gaussian posterior, will be broadcast to correct shape
        q_mu.var = 2.0 # add Gaussian noise to mean of variational Gaussian posterior to aid training N(0,q_mu.var)
        q_sqrt = 2.0 # cholesky of covariance of variational Gaussian posterior, will be multiplied by identity of correct shape
        q_diag = false # boolean, if true, approximate covariance by diagonal matrix
